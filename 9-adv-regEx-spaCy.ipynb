{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\"\n",
    "# this regex is to grab any thing that starts with Paul and the any word following it till the wordbreak\n",
    "pattern = r\"Paul [A-Z]\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we apply the pattern to the text\n",
    "matches = re.finditer(pattern, text)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct Spans \n",
    "(we are goin to make our custom pipe with these functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "doc = nlp(text)\n",
    "\n",
    "original_ents = list(doc.ents)\n",
    "mwt_ents = []\n",
    "\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    start, end= match.span()\n",
    "    span = doc.char_span(start,end)\n",
    "    if(span):\n",
    "        mwt_ents.append((span.start,span.end,span.text))\n",
    "for ent in mwt_ents:\n",
    "    start,end,name = ent\n",
    "    #  we now going to create a span object in spacy\n",
    "    #  that we can inject in our doc.ents list\n",
    "    per_ent = Span(doc, start, end, label=\"PERSON\")\n",
    "    original_ents.append(per_ent)\n",
    "doc.ents = original_ents\n",
    "#  now you can see that we have our entities in the label\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mwt_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can use this to create a custom component(pipe)\n",
    "that does all this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component('prince_ner')\n",
    "def prince_ner(doc):\n",
    "    pattern = r\"Paul [A-Z]\\w+\"\n",
    "    original_ents = list(doc.ents)\n",
    "    mwt_ents = []\n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end= match.span()\n",
    "        span = doc.char_span(start,end)\n",
    "        if(span):\n",
    "            mwt_ents.append((span.start,span.end,span.text))\n",
    "    for ent in mwt_ents:\n",
    "        start,end,name = ent\n",
    "        per_ent = Span(doc, start, end, label=\"PERSON\")\n",
    "        original_ents.append(per_ent)\n",
    "    doc.ents = original_ents\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lets create another blank model and add our our custom pipe to it\n",
    "nlp2 = spacy.blank('en')\n",
    "nlp2.add_pipe('prince_ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now your model has a custom pipe and you can perform the same action but this time with your doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp2(text)\n",
    "doc.ents\n",
    "#  you will see now that the output is the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets look at an error that will happen if we apply this to the spacy small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.util import filter_spans\n",
    "@Language.component('cinema_ner')\n",
    "def cinema_ner(doc):\n",
    "    pattern = r\"Hollywood\"\n",
    "    original_ents = list(doc.ents)\n",
    "    mwt_ents = []\n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end= match.span()\n",
    "        span = doc.char_span(start,end)\n",
    "        if(span):\n",
    "            mwt_ents.append((span.start,span.end,span.text))\n",
    "    for ent in mwt_ents:\n",
    "        start,end,name = ent\n",
    "        per_ent = Span(doc, start, end, label=\"CINEMA\")\n",
    "        original_ents.append(per_ent)\n",
    "    #  this now will look at all spans and if there are spans that overlap it gives priority to the long one\n",
    "    filtered = filter_spans(original_ents)\n",
    "    doc.ents = filtered\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cinema_ner(doc)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp3 = spacy.load('en_core_web_sm')\n",
    "nlp3.add_pipe('cinema_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Paul Newman, Paul Hollywood)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  if you run this code below you will get the error\n",
    "doc3 = nlp3(text)\n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error tells us that one of our tokens from the finditer() overlapped with one that our “ner” component found. This is a problem that can be rectified with spaCy’s filter_spans. This gives primacy to longer spans. Notice how we have allowed the Paul Hollywood entity to be a PERSON, rather than CINEMA. This is because Hollywood is shorter than Paul Hollywood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
